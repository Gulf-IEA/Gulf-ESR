---
title: "Metric Analysis Code"
format: html
execute: 
  echo: true
  warning: false
---

File created on 2025-10-16

# 0. Setup

Add any packages that are needed for analysis in this code chunk. 
```{r packages}
library(IEAnalyzeR)
library (here)
library(r4ss)
library(dplyr)
library(tidyr)
library(ggplot2)
library(purrr)
library(stringr)
library(rlist)
```

File Naming Setup.
!! Auto generated-Do Not Change !!
```{r}

root_name<- "SA_biomass"

csv_filename<-paste0("data/formatted/formatted_csvs/", root_name, "_formatted.csv") 
object_filename<-paste0("data/formatted/final_objects/", root_name, "_object.rds")
plot_filename<-paste0("figures/plots/", root_name, "_plot.png")

```

# 1. Read Data
Pull data from its source:
Manual data: data/unformatted data
Automated data: Add script for data call (API, package, etc.)
Confidential data: Store locally in the confidential data folder
    - This folder is excluded using gitignore and will not push to the GitHub repo
If intermediate data (shapefiles etc.) are needed, please put them in data>intermediate
    - Filename should use the syntax rootname_descriptivename
```{r}
# load helper function
source(here("scripts/helper_functions/process_SS_assessments.R"))

# Pull all assessment model outputs from Google drive folder. Only need to do this when new assessments are added or updated
#process_SS_assessments() 

#Start here if you don't need to load new assessments
SS_outputs_all = readRDS(here("data/intermediate/SS_outputs_all.rds"))
```

Remove all the older assessments, keeping only the newest ones for each species. Also remove the funky yellowtail report that was accidentally created.
```{r}
assessment_names = names(SS_outputs_all) 

# --- 1. Filter out the specific accidental report ---
# This removes the "Assessment Report.sso files_Yellowtail Snapper" entry
filtered_names = assessment_names[!grepl("Assessment Report.sso files", assessment_names)]

# --- 2. Create a Data Frame for Parsing and Sorting ---
# Create a data frame from the filtered names
df = data.frame(full_name = filtered_names) %>%
    # Extract the Species and Assessment ID
    # Species: Everything before the last '_'
    # ID: Everything after the last 'SEDAR'
    separate(full_name, 
             into = c("species", "sedar", "id_raw"), 
             sep = "_SEDAR", 
             remove = FALSE, 
             extra = "merge") %>%
    # Clean up the species name (since 'SEDAR' might have split it weirdly)
    mutate(
        # Recalculate species by dropping the trailing _SEDAR[ID]
        species = sub("(_SEDAR.*)", "", full_name), 
        # Extract the numeric part of the ID (e.g., 28 from 28U, 68 from 68OA)
        id_num = as.numeric(str_extract(id_raw, "^\\d+")),
        # Determine the complexity/newness rank of the suffix
        # Suffixes (U, OA, etc.) make an assessment newer than one with no suffix
        suffix_rank = ifelse(grepl("[A-Za-z]", id_raw), 1, 0)
    )

# --- 3. Group and Keep the Newest Assessment for Each Species ---
final_keepers = df %>%
    group_by(species) %>%
    # Arrange by numeric ID (highest is newest) then by suffix rank (1 is newest)
    # The last row in the group after sorting is the one to keep.
    arrange(id_num, suffix_rank, .by_group = TRUE) %>%
    # Keep only the last (newest) entry for each species group
    slice_tail(n = 1) %>%
    ungroup() %>%
    pull(full_name) # Extract the vector of final names to keep

# --- 4. Filter the main list ---
SS_outputs_newest = SS_outputs_all[final_keepers] 

# --- Resulting names (for verification) ---
cat("Names to keep:\n")
print(final_keepers)

saveRDS(SS_outputs_newest, here("data/intermediate/SS_outputs_newest.rds"))
```


# 2. Data Transformation
Transform the data to fit the IEA data format. 
For more info on IEA data format go HERE, or use THIS FUNCTION to view dummy data.

```{r}
# Define the output folder outside the loop
output_data_folder <- here("data/formatted/formatted_csvs")

# Get the names of the list items to iterate through
model_names <- names(SS_outputs_newest)

# Loop through each model name
for (name in model_names) {
  
  # Set the current model as 'base'
  base <- SS_outputs_newest[[name]]
  
  dir_path <- base$inputs$dir
  path_elements <- unlist(strsplit(dir_path, split = "/|\\\\"))
  path_elements <- path_elements[path_elements != ""]
  
  # The species name is the second to last element
  Species <- path_elements[length(path_elements) - 1]
  # The assessment name is the last element
  Assessment <- path_elements[length(path_elements)]
  
  # Check if timeseries data exists and has a 'Bio_smry' column
  if (!is.null(base$timeseries) && "Bio_smry" %in% colnames(base$timeseries)) {
    # Filter and process the biomass data, convert tons to million lbs
    biomass <- base$timeseries %>%
      filter(Era != "FORE") %>%
      filter(Yr >= 2000) %>%
      mutate(Bio_mil_lbs = (Bio_smry * 2204.62) / 1000000)
    
    # Check if there is data after filtering
    if (nrow(biomass) > 0) {
      
      # Format data for each assessment by area
      biomass_for_pivot = biomass %>% 
        mutate(Area_Name = paste0("Bio_Area", Area)) %>% 
        select(Yr, Area_Name, Bio_mil_lbs)
      
      pivoted_biomass = biomass_for_pivot %>% 
        pivot_wider(
          names_from = Area_Name,
          values_from = Bio_mil_lbs
        ) %>% 
        select(Yr, starts_with("Bio_Area")) %>% 
        as.data.frame()
      
      #Use the convert_cleaned_data function in IEAnalyzeR to add metadata to the data frame
      
      #set up the metadata
      num_data_cols = ncol(pivoted_biomass) - 1
      area_col_names = colnames(pivoted_biomass)[-1]
      
      indicator_text = paste0(Species, "_", Assessment, "_", "Biomass")
      indicator_names = c(rep(indicator_text, num_data_cols))
      
      unit_text = "Million pounds"
      unit_names = c(rep(unit_text, num_data_cols))
      
      extent_text = gsub("Bio_Area", "Area ", area_col_names)
      extent_names = c(extent_text)
      
      final_csv = IEAnalyzeR::convert_cleaned_data(pivoted_biomass, indicator_names, unit_names, extent_names)
      
      file_name = paste0(Species, "_", Assessment, "_", "Biomass_formatted.csv")
      write.csv(final_csv, file = file.path(output_data_folder, file_name), row.names = FALSE)
      
    } else {
      warning(paste("No data after filtering for", name))
    }
  } else {
    warning(paste("Timeseries data or 'Bio_smry' column not found for", name))
  }
  
  # Print a message to show progress
  print(paste("Processed:", name))
}
```


Combine all the biomass datasets into one data frame
```{r}
# Set the folder where .rds files are stored
input_folder = here("data/intermediate/")

# List all RDS files that match the pattern *_biomass.rds
files <- list.files(input_folder, pattern = "_biomass\\.rds$", full.names = TRUE)

#check all the files
for (file in files) {
  dat <- readRDS(file)
  print(basename(file))
  print(names(dat))
}

# Read and combine
biomass_df_list <- map(files, function(file) {
  # Read the .rds file
  dat <- readRDS(file)
  
  # Extract species_assessment from filename
  filename <- basename(file)
  name <- str_remove(filename, "_biomass\\.rds$")  # remove suffix
  
  # Keep only Yr and Bio_mil_lbs, rename Bio_mil_lbs to species_assessment name
  dat %>%
    select(Yr, Bio_mil_lbs) %>%
    rename(!!name := Bio_mil_lbs)
})

# Merge all data frames by Yr
# Reduce joins all the data frames by Yr column
combined_biomass <- reduce(biomass_df_list, full_join, by = "Yr")

# Arrange by year
combined_biomass <- combined_biomass %>% arrange(Yr)

saveRDS(combined_biomass, file = file.path(input_folder, "combined_biomass_trends.rds"))
```


# 3. Create Data_Prep object
Please use your formatted CSV to create a "data_prep" object.
For more info on the data_prep function please go HERE
```{r}
# Set the output folder
output_data_folder <- here("data/formatted/final_objects")

# Set the folder where .csv files are stored
input_folder = here("data/formatted/formatted_csvs")

# List all csv files that contain SEDAR and Biomass
files <- list.files(input_folder, full.names = TRUE)
files <- files[grepl("SEDAR", files) & grepl("Biomass", files)]

for (file in files) {
  
  filename = basename(file)
  
  file_elements = strsplit(filename, "_")[[1]]
  
  # The species name is the first element
  Species <- file_elements[1]
  # The assessment name is the second element
  Assessment <- file_elements[2]
  
  dat = read.csv(file)
  
  data_obj<-IEAnalyzeR::data_prep(dat, subind = "extent")
  
  file_name = paste0(Species, "_", Assessment, "_", "Biomass_object.rds")
  saveRDS(data_obj, file = file.path(output_data_folder, file_name))
  
}
```

# 4. Save Formatted csv and data_prep object
This will save your data to the appropriate folders. 
Please replace "formatted_csv" with the name of your final formatted data.
```{r}
#Save formatted CSV
write.csv(formatted_csv, file = csv_filename, row.names = F)

#Save data_prep object
saveRDS(data_obj, file = object_filename)
```

# 5. Preview Plot
Use the IEAnalyzeR plotting function to preview the data. This will not necessarily be the final figure used in reports.
For more info on the plot_fn_obj function go HERE
```{r}
# Set the output folder
output_data_folder <- here("figures/plots")

# Set the folder where .csv files are stored
input_folder = here("data/formatted/final_objects")

# List all rds files that contain SEDAR and Biomass
files <- list.files(input_folder, full.names = TRUE)
files <- files[grepl("SEDAR", files) & grepl("Biomass", files)]

for (file in files) {
  
  filename = basename(file)
  
  file_elements = strsplit(filename, "_")[[1]]
  
  # The species name is the first element
  Species <- file_elements[1]
  # The assessment name is the second element
  Assessment <- file_elements[2]
  
  dat = readRDS(file)
  
  plot<-IEAnalyzeR::plot_fn_obj(df_obj = dat, manual_title = paste0(Species, " ", Assessment, " ", "Biomass"), trend = TRUE, xbreaks_by = 2, fig.width = 7)
  
  file_name = paste0(Species, "_", Assessment, "_", "Biomass_plot.png")
  ggsave(plot, file = file.path(output_data_folder, file_name), height = 4, width = 7, units = "in")
  
}
```

# 6. Save plot
This will save the plot to the correct folder.
Adjust height & width using (height=, width=, unit="in") if needed.
```{r}
ggsave(filename = plot_filename)
```

