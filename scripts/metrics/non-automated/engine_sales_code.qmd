---
title: "Metric Analysis Code"
format: html
execute: 
  echo: true
  warning: false
---

File created on 2026-01-08

# 0. Setup
Add any packages that are needed for analysis in this code chunk. 
```{r packages}
library(IEAnalyzeR)
library(here)
library(ggplot2)
library(pdftools)
library(stringr)
library(dplyr)
library(tidyr)
library(purrr)
```

File Naming Setup.
!! Auto generated-Do Not Change !!
```{r}

root_name<- "engine_sales"

csv_filename<-here(paste0("data/formatted/formatted_csvs/", root_name, "_formatted.csv")) 
object_filename<-here(paste0("data/formatted/final_objects/", root_name, "_object.rds"))
plot_filename<-here(paste0("figures/plots/", root_name, "_plot.png"))

```

# 1. Read Data

Pull data from its source: Manual data: data/unformatted data. Automated data: Add script for data call (API, package, etc.). Confidential data: Store locally in the confidential data folder - This folder is excluded using gitignore and will not push to the GitHub repo. If intermediate data (shapefiles etc.) are needed, please put them in data\>intermediate - Filename should use the syntax rootname_descriptivename
```{r}
# Outboard engine sales trend data come from the National Marine Manufacturers Association. They publish a U.S. Recreational Boating Statistical Abstract annually. The pdf can be dowloaded from [here](https://www.nmma.org/statistics/publications/statistical-abstract). You must create an account in order to download the pdfs. For this report, the pdf has been downloaded and saved to the data/unformatted folder.

# We will start by extracting all the relevant data, then will summarize to make an indicator.

file_path <- here("data/unformatted/2024 Outboard Engine Sales Trends.pdf")

# First I need a function to scrape the data from any of the tables in the pdf. This function will scrape annual sales data from the Gulf states. Luckily the tables seem to always be in a consistent format.

# Function to extract state-specific outboard sales by page/table
extract_hp_data <- function(file_path, page_num) {
  
  #suppress warning here about the font (not necessary)
  pdf_text_raw <- suppressMessages(suppressWarnings(pdftools::pdf_text(file_path)[page_num]))
  lines <- str_split(pdf_text_raw, "\\n")[[1]]
  lines <- str_trim(lines)
  
  # 1. Title Extraction
  title_line <- lines[str_detect(lines, "^Table \\d+:")]
  if(length(title_line) > 0) {
    clean_title <- str_match(title_line[1], ":\\s*(.*?)\\s*unit sales")[,2]
  } else {
    clean_title <- paste("Segment_Page", page_num)
  }
  
  target_states <- c("Alabama", "Florida", "Louisiana", "Mississippi", "Texas")
  
  scrape_row <- function(state_name) {
    # 2. Targeted Regex: Starts with state name and ends with numeric rank
    pattern <- paste0("^[\"\\s]*", state_name, ".*\\d$")
    row_text <- lines[str_detect(lines, pattern)]
    
    # Fallback if rank column is missing or text layout is slightly shifted
    if(length(row_text) == 0) {
       pattern <- paste0("^[\"\\s]*", state_name)
       potential_rows <- lines[str_detect(lines, pattern)]
       if(length(potential_rows) == 0) return(rep(NA, 14))
       # Take the longest matching line (likely the table row)
       row_text <- potential_rows[which.max(nchar(potential_rows))]
    }
    
    # 3. Handling Dashes and Numbers
    # Remove state name from the start to avoid numeric interference
    just_data_text <- str_remove(row_text, paste0("^[\"\\s]*", state_name))
    
    # 4. Handle Unicode Em-dashes and Numbers
    # Regex for: 
    # (a) Numbers/Commas: -?[\\d,.]+
    # (b) Unicode Dash Placeholders: [\u2014\u2013]
    values <- str_extract_all(just_data_text, "-?[\\d,.]+|[\u2014\u2013]")[[1]]
    
    # Convert to numeric or NA
    clean_vals <- sapply(values, function(x) {
      # If it's a dash or hyphen, it's missing data for that year
      if (x %in% c("\u2014", "\u2013", "-")) return(NA)
      # Otherwise clean commas and convert to numeric
      return(as.numeric(gsub(",", "", x)))
    })
    
    # Remove the string labels
    numeric_vals <- unname(clean_vals)
    
    # 4. Return 2011-2024 (the first 14 columns of data)
    if(length(numeric_vals) >= 14) {
      return(as.numeric(numeric_vals[1:14]))
    } else {
      # If for some reason the row is short, pad with NA
      return(as.numeric(c(numeric_vals, rep(NA, 14 - length(numeric_vals)))))
    }
  }
  
  data_list <- lapply(target_states, scrape_row)
  names(data_list) <- target_states
  
  df <- data.frame(
    year = 2011:2024,
    Texas = data_list$Texas,
    Louisiana = data_list$Louisiana,
    Mississippi = data_list$Mississippi,
    Alabama = data_list$Alabama,
    Florida = data_list$Florida
  )
  
  return(list(name = clean_title, data = df))
}


# Now we will use this function to extract sales data for all the different engine sizes.There are 10 tables ranging from 4hp engine sales to 300+hp. 

#The tables are on every other page starting on page 21 for the 2024 report.
page_numbers = seq(21,41, by=2)

hp_data_list <- list()

for (p in page_numbers) {
  tryCatch({
    result <- extract_hp_data(file_path, p)
    hp_data_list[[result$name]] <- result$data
    message("Successfully scraped: ", result$name)
  }, error = function(e) {
    message("Error on page ", p, ": ", e$message)
  })
}

```

# 2. Clean data and create time series csv

Transform the data to fit the IEA data format.
For more info on IEA data format go to the IEAnalyzeR vignette [HERE](https://gulf-iea.github.io/IEAnalyzeR/articles/How_to_use_IEAnalyzeR.html).
Once data are formatted with time (annual or monthly) as column 1 and metric values in the remaining columns, you can use the function convert_cleaned_data to convert your csv into a format that can be read by the data_prep function.
```{r}
#Now that we've scraped the data from all the relevant tables, we want to combine the information into an indicator. We will combine all Gulf states and just look at three categories of engine sizes. Small = Less than 30hp, Medium = 30-149.9hp, Large = 150+hp. 

# Define the mapping of HP ranges to Categories
category_map <- list(
  "<30 hp"    = c("Less than 4 hp", "4–9.9 hp", "10–29.9 hp"),
  "30-150 hp" = c("30–49.9 hp", "50–74.9 hp", "75–99.9 hp", "100–149.9 hp"),
  ">150 hp"   = c("150–199.9 hp", "200–249.9 hp", "250–299.9 hp", "300 hp and greater")
)

# Process the list into 4-column table
outboard_summary <- hp_data_list %>%
  # Convert list of dataframes into one long dataframe
  imap_dfr(~ .x %>% mutate(segment = .y)) %>%
  # Create the new category labels
  mutate(category = case_when(
    segment %in% category_map[["<30 hp"]]    ~ "<30 hp",
    segment %in% category_map[["30-150 hp"]] ~ "30-150 hp",
    segment %in% category_map[[">150 hp"]]   ~ ">150 hp"
  )) %>%
  # Row-wise sum of the 5 states, then group-wise sum by category
  mutate(five_state_total = Texas + Louisiana + Mississippi + Alabama + Florida) %>%
  group_by(year, category) %>%
  summarise(total_sales = sum(five_state_total, na.rm = TRUE), .groups = "drop") %>%
  # Pivot to wide format to match your requested column structure
  pivot_wider(names_from = category, values_from = total_sales) %>%
  # Ensure columns are in the specific order you requested
  select(year, `<30 hp`, `30-150 hp`, `>150 hp`)

head(outboard_summary)

```

```{r}
#Define header components for the data rows (ignore year). Fill in the blanks here.
indicator_names = rep("Boat sales by engine size", ncol(outboard_summary)-1)
unit_names = rep("units sold", ncol(outboard_summary)-1)
extent_names = c("<30 hp", "30-150 hp", ">150 hp")

formatted_data = IEAnalyzeR::convert_cleaned_data(outboard_summary, indicator_names, unit_names, extent_names)
```

# 3. Save Formatted data as csv

This will save your data to the appropriate folder.
```{r}
write.csv(formatted_data, file = csv_filename, row.names = F)
```


# 4. Create Data_Prep object

Please use your formatted csv to create a "data_prep" object.
For more info on the data_prep function see the vignette linked above.
```{r}
data_obj<-IEAnalyzeR::data_prep(csv_filename, subind = "extent")
```

# 5. Save Formatted data_prep object

This will save your data to the appropriate folder.
```{r}
saveRDS(data_obj, file = object_filename)
```

# 6. Preview Plot

Use the IEAnalyzeR plotting function to preview the data.
This will not necessarily be the final figure used in reports.
For more info on the plot_fn_obj function go HERE

```{r}
IEAnalyzeR::plot_fn_obj(df_obj = data_obj, trend = TRUE)
```

# 7. Save plot

This will save the plot to the correct folder.
Adjust height & width using (height=, width=, unit="in") if needed.

```{r}
ggsave(filename = plot_filename)
```
